

# Initial set up

Set working directory
```{r setup}
knitr::opts_knit$set(root.dir = "C:/Users/benji/Desktop/Regrid")
```

Load packages
```{r}
library(sf)
library(tidyverse)
library(terra)
library(exactextractr)
library(stringdist)
library(openxlsx)
library(tigris)
library(stringdist)
library(fastcluster)
library(raster)
library(tmap)
```

Set universal variables
```{r}
#unit conversions
gpm_to_lps = 0.0630902
ft_to_m = 0.3048
ha_to_m2 = 10000

crs = 3310 #NAD83 California Albers project
cropland_threshold = 0.05 #threshold of proportion of parcel area that is cropland in order to be considered a cropland parcel
area_threshold = 2 #minimum hectares for parcel area

tmap_mode("view")
```

# Import and process data

## Central Valley counties

Get polygons for central valley counties
```{r, eval = F}
central_valley_counties = str_to_lower(c("Butte", "Colusa", "Glenn", "Fresno", "Kern", "Kings", "Madera", "Merced", "Placer", "Sacramento", "San_Joaquin", "Shasta", "Stanislaus", "Sutter", "Tehama", "Tulare", "Yolo", "Yuba"))

ca_counties = st_transform(counties(state = "CA", year = 2020, class = "sf"), crs)%>%
  filter(NAME %in% str_to_title(central_valley_counties) | NAME == "San Joaquin")

st_write(ca_counties, "Data/Central Valley counties/central_valley_counties.gpkg")
```

## Precipitation

Precipitation raster (annual) spans 1981-2023 and is from CHIRPS
```{r}
precip = rast("Data/Precipitation/chirps-v2.0.annual.nc")
```


## GW basins

Import spatial data for Bulletin 118 Groundwater Basin Boundaries (obtained from [CA DWR](https://water.ca.gov/programs/groundwater-management/bulletin-118))

Filter for only gw basins intersecting with Central Valley counties

```{r, eval = F}
gw_basins = st_transform(st_read("Data/GW basins/Raw/i08_B118_v6_2.shp"), crs)%>%
  dplyr::select(1:4)%>%
  rename(basin_number = 1, subbasin_number = 2, basin_name = 3, subbasin_name = 4)%>%
  filter(basin_name %in% c("SACRAMENTO VALLEY", "SAN JOAQUIN VALLEY"))

subbasin_precip_means <- exact_extract(crop(precip, ext(gw_basins)), gw_basins, 'mean', force_df = TRUE)%>%
  rename_with(~ as.character(1981:2023))%>%
  mutate(mean_annual_precip = rowMeans(across(everything())))%>%
  pull(mean_annual_precip)

gw_basins = gw_basins%>%
  mutate(mean_annual_precip = subbasin_precip_means)%>%
  filter(basin_number %in% c("5-022", "5-021"))
```

We can also bring in data on which subbasins have been designated as critically overdrafted by CA DWR. [Data here](https://water.ca.gov/Programs/Groundwater-Management/Bulletin-118/Critically-Overdrafted-Basins)

Critically overdramed subbasins obtained from [CA Dept of Water
Resources](https://water.ca.gov/-/media/DWR-Website/Web-Pages/Programs/Groundwater-Management/Basin-Prioritization/Files/CODBasins_websitemapPAO_a_20y.pdf)
```{r, eval = F}
overdrafted_subbasins = c("5-022.01", "5-022.04", "5-022.05", "5-022.06", "5-022.07", "5-022.08", "5-022.09", "5-022.11", "5-022.12", "5-022.13", "5-022.14", "6-054")

gw_basins = gw_basins%>%
  mutate(critically_overdrafted = as.factor(ifelse(subbasin_number %in% overdrafted_subbasins, 1, 0)))

st_write(gw_basins, "Data/GW basins/Filtered/filtered_gw_basins.gpkg", delete_dsn = T)
gw_basins = st_read("Data/GW basins/Filtered/filtered_gw_basins.gpkg")
```


## Crop raster

Crop raster from [2023 Cropland CROS (USDA)](https://croplandcros.scinet.usda.gov/). Import and reclassify to binary (cropland or not cropland)

```{r, eval = F}
cropland_extent_raster = rast("Data/Crop data/crops_3311.TIF")
#levels(cropland_extent_raster)
reclass_matrix = cbind(c(59,92,111,112,121,122,123,124,131,141,142,143,152,176,190,195), 0)

cropland_extent_raster_binary = classify(cropland_extent_raster, reclass_matrix, others = 1)

writeRaster(cropland_extent_raster_binary, "Crop data/crops croplandcros/cropland_binary.tif")
```


## Cropland parcels

Generate list of all Regrid Central Valley land parcel geopackages

```{r, eval = F}
gpkg_files = list.files("Data/Parcels/Raw/", pattern = "\\.gpkg$", full.names = T)

central_valley_gpkgs = Filter(function(file) any(sapply(central_valley_counties, function(county) grepl(county, file))), gpkg_files)
```

Keep only relevant columns. Descriptions of Regrid column names [here](https://docs.google.com/spreadsheets/d/14RcBKyiEGa7q-SR0rFnDHVcovb9uegPJ3sfb3WlNPc0/edit#gid=942435131)

```{r}
#colnames(st_read("Data/Parcels/Raw/ca_yuba.gpkg")%>%data.frame())

columns = c("parcelnumb", "parcelnumb_no_formatting", "alt_parcelnumb1", "alt_parcelnumb2", 
             "alt_parcelnumb3", "usedesc", "parvaltype", "improvval", "landval", "parval", 
             "agval", "saleprice", "saledate", "owntype", "owner", "ownfrst", "ownlast", 
             "owner2", "owner3", "owner4", "mailadd", "mail_address2", "careof", 
             "mail_addno", "mail_addpref", "mail_addstr", "mail_addsttyp", "mail_addstsuf", 
             "mail_unit", "mail_city", "mail_state2", "mail_zip", "address", "address2", 
             "saddno", "saddpref", "saddstr", "saddsttyp", "saddstsuf", "sunit", "scity", 
             "original_address", "city", "county", "szip", "cdl_raw", "cdl_majority_category", 
             "cdl_majority_percent", "cdl_date", "ll_gisacre")
```

Go through the parcels geopackage for each Central Valley county, filtering for only parcels intersecting the gw basins of interest. For each parcel, calculate the fraction of the parcel that is cropland (based on our binary cropland raster above). Label parcels as "cropland parcels" if at least 10% of the parcel area is designated as cropland. This is to avoid designating parcels as cropland parcels in cases where a tiny portion is cropland or a few grid cells are mistakenly classified as cropland in the Cropland CROS raster. Combine cropland parcels from all Central Valley counties into one large dataset of cropland parcels.

```{r, eval = F}
start_time = Sys.time()

master_cropland_parcels = lapply(central_valley_gpkgs, function(file) {
  county_name = str_to_title(gsub("_", " ", gsub("ca_|\\.gpkg", "", basename(file))))
  cat(county_name, "County\n")

  return(st_transform(st_read(file, quiet = T), crs) %>%
    dplyr::select(all_of(columns))%>%
    filter(ll_gisacre >= 5)%>%
    st_filter(., gw_basins, .pred = st_intersects)%>%
    mutate(fraction_cropland = exact_extract(cropland_extent_raster_binary, ., 'mean'), 
         parcel_area_ha = ll_gisacre * 0.404686, 
         cropland_parcel = ifelse(fraction_cropland > cropland_threshold, 1, 0))%>%
    filter(cropland_parcel == 1))})

master_cropland_parcels = do.call(rbind, master_cropland_parcels)%>%
  separate(address, into = c("address_no", "address_st"), sep = " ", extra = "merge", convert = T, remove = F)%>%
  rename(parcel_id = parcelnumb)

end_time = Sys.time()
end_time - start_time

st_write(master_cropland_parcels, "Data/Parcels/Cropland parcels/cropland_parcels.gpkg", delete_dsn = T)
master_cropland_parcels = st_read("Data/Parcels/Cropland parcels/cropland_parcels.gpkg")
```


## Sections

Import PLSS sections (1x1 mile squares) from [California Data Portal](https://data.ca.gov/dataset/public-land-survey-system-plss-sections).
This is because most of the wells are not precisely geolocated, but rather snapped to the centroid of the section that they fall within.

Filter for sections that intersect at least 1 cropland parcel and intersect the GW basins of interest, since we don't care about wells otherwise
```{r, eval = F}
sections = st_transform(st_read("Data/Sections/Raw data/Public_Land_Survey_System_(PLSS)_3A_Sections.shp"), crs)%>%
  st_filter(., master_cropland_parcels, .pred = st_intersects)%>%
  st_filter(., gw_basins, .pred = st_intersects)%>%
  dplyr::select(MTRS, geometry)
```

## Well data

Import well data from the [USGWD](https://www.hydroshare.org/resource/8b02895f02c14dd1a749bcc5584a5c55/) dataset and from the [OSWCR](https://data.ca.gov/dataset/well-completion-reports) dataset (maintained by the CA Dept of Water Resources).

Import well data and get rid of duplicates (based on CA well ID).

```{r, eval = F}
usgwd = read.csv("Data/Wells/Raw/Chung-Yi's dataset/USGWD_California.csv")%>%
  arrange(rowSums(is.na(.)))%>%
  distinct(Well.ID..State., .keep_all = T)%>%
  rename(ca_well_id = 2)
```

Bring in OSWCR dataset for additional important covariates that are not in USGWD, such as well address details, accuracy of geolocation, etc.

```{r, eval = F}
oswcr = read.csv("Data/Wells/Raw/OSWCR/wellcompletionreports.csv")%>%
  dplyr::select(1, LLACCURACY, METHODOFDETERMINATIONLL, WELLLOCATION, CITY, PLANNEDUSEFORMERUSE, APN)%>%
  rename(ca_well_id = 1, geo_accuracy = 2, method_of_determination = 3, well_address = 4, city = 5, use_oswcr = 6)

table(oswcr$geo_accuracy)
```

Combine the 2 well datasets and turn into spatial point data

Clean up the IDs, addresses, and such (ex: turn addresses to lowercase so capitalisation won't trip up any of the well-parcel matching)

```{r, eval = F}
filtered_wells = st_transform(st_as_sf(left_join(usgwd, oswcr, by = "ca_well_id")%>%
                                   filter(!is.na(Longitude) & !is.na(Latitude)), 
                                 coords = c("Longitude", "Latitude"), crs = 4326), crs)%>%
  filter(grepl("Agriculture", use_oswcr) | use_oswcr == "Unknown")%>%
  mutate_at(vars(well_address, city), ~ na_if(., ""))%>%
  separate(well_address, into = c("address_no", "address_st"), sep = " ", extra = "merge", convert = T, remove = F)%>%
  st_join(., sections)%>%
  filter(!is.na(MTRS))%>%
  mutate(APN = gsub("[- ]", "", APN),
         well_address = str_to_lower(well_address),
         address_st = str_to_lower(address_st))%>%
  filter(Year.Well.was.Constructed > 1982)

rm(oswcr, usgwd)

st_write(filtered_wells, "Data/Wells/Processed/filtered_wells_with_section.gpkg", delete_dsn = T)
filtered_wells = st_read("Data/Wells/Processed/filtered_wells_with_section.gpkg")
```


We want to make one last update to our sections dataset: Before, we filtered for sections intersecting cropland parcels and groundwater basins of interest. Now, we want to narrow down further to those sections that also have a well in them. This will be our final 'filtered sections' dataset.

```{r, eval = F}
filtered_sections = sections%>%
  filter(MTRS %in% filtered_wells$MTRS)

rm(sections)

st_write(filtered_sections, "Data/Sections/Filtered/filtered_sections.gpkg", delete_dsn = T)
filtered_sections = st_read("Data/Sections/Filtered/filtered_PLSS_sections.gpkg")
```

Not all wells are snapped to the centroid of the section they fall in. Based on the 'geo_accuracy' column, we can pull out the wells with accuracy of coordinates 50ft or less and put a buffer around them for the later matching steps. For example, for a well with accuracy 2.5ft, we can only consider matching that well to parcels within a 2.5ft buffer around that well.

```{r}
distances_less_than_50_ft = c("0.1 Ft", "10 Ft", "2.5 Ft", "20 Ft", "5 Ft", "50 Ft")

well_buffer = filtered_wells%>%
  filter(geo_accuracy %in% distances_less_than_50_ft)%>%
  mutate(buffer_distance = as.numeric(gsub("\\s*\\w*$", "", geo_accuracy))*ft_to_m)%>%
  mutate(geometry = st_buffer(geometry, dist = buffer_distance))%>%
  dplyr::select(ca_well_id, MTRS, geometry)%>%
  rename(well_MTRS = MTRS)

st_write(well_buffer, "Data/Wells/Processed/well_buffer.gpkg", delete_dsn = T)
```

## Filtered parcels

Our master cropland parcels dataset will be great for analysis just concerning land (ex: relationship between precipitation and farm size).
However, for land-water analysis, some of the wells could be matched to non-cropland parcels. We'll ultimately want to exclude these wells/parcels, but we don't want to mistakenly match a well with a cropland parcel when its 'true' match was with a non-cropland parcel. Therefore, for future matching steps, we want to get a dataset of all parcels (cropland and non-cropland) that intersect any sections with wells in them (aka, our final 'filtered sections' dataset).

Here, similar to the cropland parcel iteration above, we go through each county. We filter for parcels that intersect with our 'filtered_sections' dataset and designate parcels as cropland parcels or not. We do some processing on parcel addresses to help with our matches by address later on. Finally, we combine the filtered parcels from all Central Valley counties into one dataset!

We also want to make sure that each parcel has a unique ID, since the parcel IDs in the Regrid dataset can be duplicated in some cases.

```{r, eval = F}
start_time = Sys.time()

filtered_parcels = lapply(central_valley_gpkgs, function(file) {
  county_name = str_to_title(gsub("_", " ", gsub("ca_|\\.gpkg", "", basename(file))))
  cat(county_name, "County\n")

  return(st_transform(st_read(file, quiet = T), crs) %>%
    dplyr::select(all_of(columns))%>%
    st_filter(., filtered_sections, .pred = st_intersects)%>%
    mutate(fraction_cropland = exact_extract(cropland_extent_raster_binary, ., 'mean'), 
         parcel_area_ha = ll_gisacre * 0.404686, 
         cropland_parcel = ifelse(fraction_cropland > cropland_threshold, 1, 0))%>%
    separate(address, into = c("address_no", "address_st"), sep = " ", extra = "merge", convert = T, remove = F)%>%
    rename(parcel_id = parcelnumb))})

filtered_parcels = do.call(rbind, filtered_parcels)%>%
  mutate(my_parcel_num = row_number())

end_time = Sys.time()
end_time - start_time

st_write(filtered_parcels, "Data/Parcels/Filtered parcels/filtered_parcels.gpkg", delete_dsn = T)
filtered_parcels = st_read("Data/Parcels/Filtered parcels/filtered_parcels.gpkg")
```


Now, let's run a spatial join of these filtered parcels with the section they intersect. 

If a parcel intersects 2 sections, this will create a duplicate row for that parcel (ie: the parcel will have two rows, one for each section it intersects). We want this because we want to consider all possible sections a parcel could intersect rather than just the one it has most overlap with.

Also, we want to clean up the IDs, addresses, and such (ex: turn addresses to lowercase so capitalisation won't trip up any of the well-parcel matching)

```{r, eval = F}
filtered_parcels_with_section = filtered_parcels%>%
  st_join(., filtered_sections)%>%
  mutate(parcel_id = gsub("[- ]", "", parcel_id), 
         parcelnumb_no_formatting = gsub("[- ]", "", parcelnumb_no_formatting),
         address = str_to_lower(address),
         mailadd = str_to_lower(mailadd),
         address_st = str_to_lower(address_st),
         owner = str_to_lower(owner))

st_write(filtered_parcels_with_section, "Data/Parcels/Filtered parcels/filtered_parcels_with_sections.gpkg", delete_dsn = T)
filtered_parcels_with_section = st_read("Data/Parcels/Filtered parcels/filtered_parcels_with_sections.gpkg")
```

Now, using a spatial join, let's create a dataset of parcels that intersect with the designated buffer of any of the wells that had a geolocation geoaccuracy 50ft or less (which are make up the 'well_buffer' dataset). In cases where there are multiple rows for a given parcel, only keep the row where the section code (MTRS) matches that of the well whose buffer the parcel intersects.

```{r, eval = F}
well_buffer_parcels = st_filter(filtered_parcels_with_section, well_buffer%>%dplyr::select(ca_well_id, well_MTRS), .pred = st_intersects)%>%
  st_join(., well_buffer)%>%
  data.frame()%>%
  filter(MTRS == well_MTRS)

st_write(well_buffer_parcels, "Data/Parcels/Filtered parcels/parcels_intersecting_well_buffer.gpkg", delete_dsn = T)
well_buffer_parcels = st_read("Data/Parcels/Filtered parcels/parcels_intersecting_well_buffer.gpkg")
```

```{r}
well_buffer_parcels_ids = unique(well_buffer_parcels$ca_well_id)
```

Lastly, let's update our cropland parcels dataset using spatial joins, so that it contains columns for mean annual precipitaiton, the gw basin and section that the parcel has the largest overlap with.
```{r, eval = F}
parcel_precip_means <- exact_extract(crop(precip, ext(master_cropland_parcels)), master_cropland_parcels, 'mean', force_df = TRUE)%>%
  rename_with(~ as.character(1981:2023))%>%
  mutate(mean_annual_precip = rowMeans(across(everything())))%>%
  pull(mean_annual_precip)

master_cropland_parcels = master_cropland_parcels%>%
  mutate(mean_annual_precip = parcel_precip_means)

master_cropland_parcels_covariates = master_cropland_parcels%>%
  st_join(., gw_basins%>%dplyr::select(basin_name:subbasin_name), join = st_intersects, largest = T)
  #st_join(., filtered_sections%>%dplyr::select(MTRS)%>%rename(parcel_MTRS = 1), join = st_intersects, largest = T)


st_write(master_cropland_parcels_covariates, "Data/Parcels/Cropland parcels/master_cropland_parcels_w_covariates.gpkg", row.names = F, delete_dsn = T)
master_cropland_parcels_covariates = st_read("Data/Parcels/Cropland parcels/master_cropland_parcels_w_covariates.gpkg")
```



# Matching wells with parcels

## Matching loop

Create an empty dataframe for each well and the section it falls in that we will populate with the parcel number it gets matched with (if any) and the matching method.

```{r, eval = F}
loop_matches = data.frame(my_parcel_num = NA, ca_well_id = filtered_wells$ca_well_id, string_dist = NA, match_method = NA, section = filtered_wells$MTRS)%>%
  mutate(row_id = row_number())

duplicate_parcels_list = list()
```

Loop through each well in our filtered well dataset. For each well, generate a dataframe of all the parcels that intersect with that well's section or the buffer around that well if applicable.

Then, for each well, we go through our hierarchy for matching methods:
1. First priority is if the well's section or buffer only has one parcel in it (which makes it easy for us!).
2. Second is if the APN (Assessor Parcel Numbers) of the well and parcel address perfectly match.
3. Third is if well address is a perfect match with a parcel in that section's address or mailing address.
4. Fourth is if the number in the well and parcel address number is the exact same and the street name is very similar (less than 0.3 based on Jaro-Winkler string distance)

Export our completed match dataset
```{r, eval = F}
for (i in 1:nrow(filtered_wells)) {
  
  well = filtered_wells[i, ]
  
  #Get intersecting parcels
  if (well$ca_well_id %in% well_buffer_parcels_ids) {
    intersecting_parcels = filter(well_buffer_parcels, ca_well_id == well$ca_well_id)}
  else {
    intersecting_parcels = filter(filtered_parcels_with_section, MTRS == well$MTRS)}
  
  #Route 1: section only has 1 parcel in it
  if (grepl("Irrigation", well$USGS.Water.Use.Category)){
    intersecting_parcels_route1 = filter(intersecting_parcels, cropland_parcel == 1)}
  else{intersecting_parcels_route1 = intersecting_parcels}
  
  if (nrow(intersecting_parcels_route1) == 1) {
    loop_matches$my_parcel_num[i] = intersecting_parcels_route1$my_parcel_num
    loop_matches$match_method[i] = if (well$ca_well_id %in% well_buffer_parcels_ids) "1 parcel in well buffer" else "1 parcel in section"
    next} 
  
  #Route 2: APN match
  if (!is.na(well$well_address) & well$well_address != ""){
    apn_match = intersecting_parcels$parcel_id == well$APN | intersecting_parcels$parcelnumb_no_formatting == well$APN | intersecting_parcels$parcelnumb_no_formatting == sub("000$", "", well$APN)
  apn_match[is.na(apn_match)] = FALSE
    if (any(apn_match, na.rm = T)) {
      loop_matches$my_parcel_num[i] = intersecting_parcels$my_parcel_num[apn_match][1]
      loop_matches$match_method[i] = "APN match"
      
      if (length(intersecting_parcels$my_parcel_num[apn_match]) > 1) {
        for (parcel_id in intersecting_parcels$my_parcel_num[apn_match]) {
          duplicate_parcels_list[[length(duplicate_parcels_list) + 1]] = data.frame(type = "APN", id = parcel_id, i = i)}}
      next}}
  
  #Route 3: well address is a perfect match with parcel address or mail address of parcel in section
  address_match <- intersecting_parcels$address == well$well_address | intersecting_parcels$mailadd == well$well_address
  address_match[is.na(address_match)] = F
  if (any(address_match, na.rm = T)) {
    loop_matches$my_parcel_num[i] <- intersecting_parcels$my_parcel_num[address_match][1]
    loop_matches$match_method[i] <- "Perfect address match"
    
    if (length(intersecting_parcels$my_parcel_num[address_match]) > 1) {
        for (parcel_id in intersecting_parcels$my_parcel_num[address_match]) {
          duplicate_parcels_list[[length(duplicate_parcels_list) + 1]] = data.frame(type = "Address", id = parcel_id, i = i)}}
      next}
  
  # Route 4: string distance
  if (!is.na(well$address_no) & !is.na(well$address_st)){
    intersecting_parcels = intersecting_parcels%>%
      filter(address_st != "" & !is.na(address_st) & address_no != "0")
  
    address_number_match = intersecting_parcels$address_no == well$address_no
    address_number_match[is.na(address_number_match)] = F
    if (any(address_number_match, na.rm = T)) {
      distances = stringdist(well$address_st, intersecting_parcels$address_st[address_number_match], method = "jw")
      min_dist = which.min(distances)
  
      if (distances[min_dist] < 0.3) {
        loop_matches$my_parcel_num[i] <- intersecting_parcels$my_parcel_num[address_number_match][min_dist]
        loop_matches$match_method[i] <- "String distance match"
        loop_matches$string_dist[i] <- distances[min_dist]
        next}}}}

#write.csv(loop_matches, "Data/Well-parcel matches/full_loop_matches.csv", row.names = F)
#loop_matches = read.csv("Data/Well-parcel matches/full_loop_matches.csv")

table(loop_matches$match_method)
```

Let's run some quick diagnostics to get a sense of how many matches we got for each method
```{r}
table(loop_matches%>%filter(!is.na(my_parcel_num))%>%
  left_join(., filtered_wells%>%dplyr::select(ca_well_id, APN), by = "ca_well_id")%>%
  #left_join(., filtered_parcels_with_section%>%select(my_parcel_num, parcel_id, parcelnumb_no_formatting, MTRS), by = c("my_parcel_num" = "my_parcel_num", "section" = "MTRS"))%>%
  pull(match_method))

loop_matches%>%filter(!is.na(my_parcel_num))%>%
  left_join(., filtered_wells%>%select(ca_well_id, APN), by = "ca_well_id")%>%
  left_join(., filtered_parcels_with_section%>%select(my_parcel_num, parcel_id, parcelnumb_no_formatting, MTRS), by = c("my_parcel_num" = "my_parcel_num", "section" = "MTRS"))
```

## Geocoding

The fifth and final method we'll used to match wells and parcels is geocoding well addresses. 

Prepare and export any remaining unmatched wells as an excel file to read into ArcGIS for geocoding. Filter out any wells whose addresses are ungeocodable (ex: any part of the address is NA)

```{r, eval = F}
wells_to_geocode = filtered_wells%>%
  filter(ca_well_id %in% (loop_matches%>%filter(is.na(my_parcel_num))%>%pull(ca_well_id)) & !is.na(well_address) & address_no != 0 & grepl("^[0-9]+$", address_no) & !is.na(city))%>%
  mutate(state = "CA")

write.xlsx(wells_to_geocode%>%select(ca_well_id, well_address, city, state), 'Well-parcel matches/Geocoding/wells_to_geocode.xlsx', row.names = FALSE)
```

Conducted the geocoding in ArcGIS Pro, yielding a point shapefile. We can now import this shapefile back into R and only keep wells that got filtered
to an actual address (rather than an intersection, POI, etc., which would mess up our spatial join with parcels). 
```{r, eval = F}
geocoded_wells = st_transform(st_read("Data/Well-parcel matches/Geocoding/Geocoded well addresses/geocoded_wells.shp"), crs = crs)%>%
  filter(!is.na(Addr_type) & !Addr_type %in% c("StreetName", "StreetMidBlock", "Locality", "StreetInt", "POI") & Score > 90)%>%
  dplyr::select(USER_ca_we)%>%
  rename(ca_well_id = 1)
```

Spatially join geocoded wells to the respective parcels they fall in
```{r, eval = F}
geocoded_wells_joined = geocoded_wells%>%
  st_join(., filtered_parcels%>%dplyr::select(my_parcel_num), join = st_within)%>%
  filter(!is.na(my_parcel_num))%>%
  rename(my_parcel_num_geocoded = 2)%>%
  data.frame()%>%dplyr::select(-geometry)
```


## Combine all matches together

Join matches with geocoded matches. For any wells that didn't get matched but had a geocode match, use geocoded parcel number, otherwise keep original match.

```{r, eval = F}
final_matches = loop_matches%>%
  left_join(., geocoded_wells_joined, by = "ca_well_id") %>%
  mutate(
    match_method = ifelse(is.na(my_parcel_num) & !is.na(my_parcel_num_geocoded), "Geocoded", match_method),
    my_parcel_num = ifelse(is.na(my_parcel_num), my_parcel_num_geocoded, my_parcel_num))%>%
  filter(!is.na(my_parcel_num))

write.csv(final_matches, "Data/Well-parcel matches/all_matches.csv", row.names = F)
final_matches = read.csv("Data/Well-parcel matches/all_matches.csv")
```

Now we can join the final match dataset with the relevant well data by well ID (we'll bring the parcel data in in a bit). Make sure that all well-related variables are metric.
```{r}
final_matches_joined = final_matches%>%
  left_join(., filtered_wells%>%data.frame()%>%
              mutate(well_depth_m = Well.Depth..Feet. * ft_to_m, well_capacity_lps = Well.Capacity..GPM. * gpm_to_lps)%>%
              rename(well_year = Year.Well.was.Constructed)%>%
              dplyr::select(ca_well_id, well_depth_m, well_capacity_lps, well_year,
                     USGS.Water.Use.Category), 
            by = "ca_well_id")

write.csv(final_matches_joined, "Data/Well-parcel matches/final_matches_joined.csv", row.names = F)
final_matches_joined = read_csv("Data/Well-parcel matches/final_matches_joined.csv")
```

# Final processing

## Prepare parcels for join with matched wells

Now we want to join in all relevant info to create our comprehensive well-parcel dataset with all covariates.

First, prepare relevant parcel data to join to matches. We want to filter for only parcels whose parcel_numbers are in our final match dataset. Then, we can join each parcel to the GW subbasin that it has the largest overlap with. Finally, we select only the variables of interest for subsequent analysis. I run the spatial join here as opposed to when I initally created filtered_parcels because running the spatial joins only on matched parcels means the spatial join is less computationally intensive. 
```{r}
filtered_parcels_with_covariates = filtered_parcels%>%
  filter(my_parcel_num %in% final_matches$my_parcel_num)%>%
  st_join(., gw_basins, join = st_intersects, largest = T)%>%
  st_join(., filtered_sections%>%dplyr::select(MTRS)%>%rename(parcel_MTRS = 1), join = st_intersects, largest = T)%>%
  dplyr::select(usedesc:agval, owner:owner4, cdl_majority_category:cdl_majority_percent, fraction_cropland:my_parcel_num, basin_name:parcel_MTRS)

st_write(filtered_parcels_with_covariates, "Data/Parcels/Filtered parcels/filtered_parcels_with_covariates.gpkg", delete_dsn = T)
filtered_parcels_with_covariates = st_read("Data/Parcels/Filtered parcels/filtered_parcels_with_covariates.gpkg")
```
## Exclude public land 

The next step is to combine all our prepared datasets and exclude public lands from our final dataset.

To do so, let's see who the largest landowners are, and we can exclude those that are evidently public land
```{r}
cropland_parcels_filtered_owners%>%
  filter(!grepl(exclude_owners, owner) & !is.na(owner))%>%
  group_by(owner)%>%
  summarise(area_ha = sum(parcel_area_ha))%>%
  arrange(-area_ha)
```

Based on a scan of this table, we can make a list of owners or types of owners that we want to classify as public land, such as counties, school districts, public universities, etc.
```{r}
exclude_owners = c("U S A|CITY OF|UNIVERSITY OF|COUNTY OF|DEPT OF|STATE OF|SAN JOSE UNIFIED|USA 101|CALIFORNIA STATE|U C D|POSTAL SERVICE|SANITATION DIST|WATER DIST|SERVICES DISTRICT|ST OF CA|UNITED STATES|WMA|WATER AGENCY|IRRIGATION DISTRICT")

master_cropland_parcels_covariates%>%
  group_by(owner)%>%
  reframe(total_area = sum(parcel_area_ha, na.rm = T))%>%
  arrange(-total_area)
  
```

Now, we can exclude these public landowners from our combined dataset, for both parcels matched with wells and our master cropland parcels layer.
```{r}
filtered_parcels_filtered_owners = filtered_parcels_with_covariates%>%
  filter(!grepl(exclude_owners, owner) & !is.na(owner) & parcel_area_ha > area_threshold & fraction_cropland > cropland_threshold)%>%
  mutate(cropland_area = parcel_area_ha*fraction_cropland)

cropland_parcels_filtered_owners = master_cropland_parcels_covariates%>%
  filter(!grepl(exclude_owners, owner) & !is.na(owner) & !owner %in% exclude_owners)%>%
  mutate(cropland_area = parcel_area_ha*fraction_cropland)
```

## Clean and standardise owner names

Another quick processing step is to clean up some of the owner names before we aggregate well and parcel statistics by owner. Some parcels might have the same owner but differ in the registered owner name by suffixes like 'Co' as opposed to 'Company', 'Limited' instead of 'LTD', etc. So we are going to trim off any of these suffixes and also get rid of white spaces, again for both well-parcel matches and the master cropland parcels layer.
```{r}
terms_to_remove = c("LLC", "LP", "TRUST", "INC", "COMPANY", "ASSOCIATES", "PARTNERS", "LIMITED", "CO", "ET AL", "ETAL", "I.D. NUMBER", "LLC", "L P", "TRUSTEE", "TRUSTEES", "TRS", "TR", "PARTNERSHIP", "LTD", "COTRUSTEE", "FAMILY", "TRSUTEE", "ESTATE", "LIFE EST", "FMLY")

pattern = paste0("\\b(", paste(terms_to_remove, collapse = "|"), ")\\b")
```

We can then calculate another Jaro-Winkler distance to detect any owner names that are extremely similar and flag them as the same owner
```{r}
# Clean the owner names
filtered_parcels_filtered_owners <- filtered_parcels_filtered_owners %>% 
  mutate(
    owner = gsub("[-()&]", "", owner),
    cleaned_owner = trimws(gsub(pattern, "", trimws(owner), ignore.case = TRUE)),
    cleaned_owner = gsub("[-()&]", "", cleaned_owner),
    cleaned_owner = gsub("[[:space:][:punct:]]", "", cleaned_owner))

# Split by subbasin and process each group separately
processed_owners <- filtered_parcels_filtered_owners %>%
  group_by(subbasin_name) %>%
  group_modify(~ {
    # Get unique cleaned owner names within this subbasin
    unique_owners <- unique(.x$cleaned_owner)
    
    # Skip processing if only one unique owner in this subbasin
    if (length(unique_owners) <= 1) {
      return(.x %>% mutate(final_owner = cleaned_owner))}
    
    # Compute pairwise Jaro-Winkler distances within this subbasin
    dist_matrix <- stringdist::stringdistmatrix(unique_owners, unique_owners, method = "jw")
    
    # Apply hierarchical clustering within this subbasin
    hc <- fastcluster::hclust(as.dist(dist_matrix), method = "average")
    
    # Define similarity threshold
    threshold <- 0.1
    clusters <- cutree(hc, h = threshold)
    
    # Create name mapping for this subbasin
    name_mapping <- data.frame(
      cleaned_owner = unique_owners, 
      cluster = clusters, 
      stringsAsFactors = FALSE
    ) %>%
      group_by(cluster) %>%
      mutate(standardized = first(cleaned_owner)) %>%
      ungroup() %>%
      dplyr::select(-cluster)
    
    # Merge back into this subbasin's data
    .x %>%
      left_join(name_mapping, by = "cleaned_owner") %>%
      mutate(final_owner = ifelse(is.na(standardized), cleaned_owner, standardized)) %>%
      dplyr::select(-standardized)}) %>%
  ungroup()

# Replace the original dataframe with the processed one
filtered_parcels_filtered_owners <- processed_owners

st_write(st_as_sf(filtered_parcels_filtered_owners%>%filter(parcel_area_ha > area_threshold & fraction_cropland > cropland_threshold), sf_column_name = "geom"), "Data/Parcels/Filtered parcels/filtered_parcels_filtered_owners_updated.gpkg", delete_dsn = T)
filtered_parcels_filtered_owners = st_read("Data/Parcels/Filtered parcels/filtered_parcels_filtered_owners_updated.gpkg")
```

We also apply this cleaning to the cropland parcels dataset
```{r}
cropland_parcels_filtered_owners <- cropland_parcels_filtered_owners %>% 
  mutate(owner = gsub("[-()&]", "", owner),
    cleaned_owner = trimws(gsub(pattern, "", trimws(owner), ignore.case = T)),
    cleaned_owner = gsub("[-()&]", "", cleaned_owner),
    cleaned_owner = gsub("[[:space:][:punct:]]", "", cleaned_owner),
    cropland_parcel_num = row_number())%>%
  filter(cleaned_owner != "")

# Split by subbasin and process each group separately
processed_owners <- cropland_parcels_filtered_owners %>%
  group_by(subbasin_name) %>%
  group_modify(~ {
    # Get unique cleaned owner names within this subbasin
    unique_owners <- unique(.x$cleaned_owner)
    
    # Skip processing if only one unique owner in this subbasin
    if (length(unique_owners) <= 1) {
      return(.x %>% mutate(final_owner = cleaned_owner))}
    
    # Compute pairwise Jaro-Winkler distances within this subbasin
    dist_matrix <- stringdist::stringdistmatrix(unique_owners, unique_owners, method = "jw")
    
    # Apply hierarchical clustering within this subbasin
    hc <- fastcluster::hclust(as.dist(dist_matrix), method = "average")
    
    # Define similarity threshold
    threshold <- 0.1
    clusters <- cutree(hc, h = threshold)
    
    # Create name mapping for this subbasin
    name_mapping <- data.frame(
      cleaned_owner = unique_owners, 
      cluster = clusters, 
      stringsAsFactors = FALSE
    ) %>%
      group_by(cluster) %>%
      mutate(standardized = first(cleaned_owner)) %>%
      ungroup() %>%
      dplyr::select(-cluster)
    
    # Merge back into this subbasin's data
    .x %>%
      left_join(name_mapping, by = "cleaned_owner") %>%
      mutate(final_owner = ifelse(is.na(standardized), cleaned_owner, standardized)) %>%
      dplyr::select(-standardized)}) %>%
  ungroup()

# Replace the original dataframe with the processed one
cropland_parcels_filtered_owners <- processed_owners

st_write(cropland_parcels_filtered_owners, "Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners.gpkg", delete_dsn = T)
cropland_parcels_filtered_owners = st_read("Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners.gpkg")
```

## Normalise well depth by depth to gwoundwater

Now that we've filtered the dataset down to the final selection of parcels, let's calculate the mean depth to groundwater in each parcel. This is because in addition to well depth, we'll run some of our analyses using well depth minus depth to groundwater as a robustness check, since well depth could vary significantly across both large and small areas based on depth to groundwater.

We will import Fall 2023 (the most recent currently available) depth to groundwater point data from the DWR's [SGMA Data Viewer](https://sgma.water.ca.gov/webgis/?appid=SGMADataViewer#gwlevels)
```{r}
depth_to_gw_points = st_transform(st_read("Data/Depth to Groundwater/Depth Points.shp"), crs)
depth_to_gw_raster = raster("Data/Depth to Groundwater/kriging_clip/kriging_clip.tif")

filtered_parcels_filtered_owners = filtered_parcels_filtered_owners%>%
  mutate(mean_depth_to_gw = exact_extract(depth_to_gw_raster, ., 'mean')*ft_to_m)

final_matches_joined = final_matches_joined%>%
  left_join(., filtered_parcels_filtered_owners%>%dplyr::select(my_parcel_num, mean_depth_to_gw), by = "my_parcel_num")%>%
  mutate(normalised_depth = well_depth_m - mean_depth_to_gw,
         max_depth_normalised = well_depth_m - mean_depth_to_gw)%>%
  dplyr::select(-geom)

write.csv(final_matches_joined, "Data/Well-parcel matches/final_matches_joined.csv", row.names = F)
```

## Combine parcels with wells

Now, we can have cases where there are multiple wells present within one parcel. If we joined wells to parcels 1to1 and then grouped by/reframed by owner to calculate totals, this could result in cases where one parcel's area/land value/etc. is summed up multiple times (since it would be present in multiple well's columns, even though it's just one parcel). Therefore, before joining well matches to parcels, we calculate totals for well metrics by parcel.
```{r}
final_matches_grouped_by_parcel = final_matches_joined%>%
  filter(well_year >= 1983)%>%
  group_by(my_parcel_num)%>%
  reframe(
    num_wells = n(),
    normalised_depth = sum(normalised_depth, na.rm = T),
    well_depth_m = sum(well_depth_m, na.rm = T), 
    well_capacity_lps = sum(well_capacity_lps, na.rm = T),
    max_depth = max(well_depth_m, na.rm = T),
    max_depth_norm = max(normalised_depth, na.rm = T),
    max_capacity = max(well_capacity_lps, na.rm = T),
    newest_well = as.numeric(min(well_year, na.rm = T)))%>%
  ungroup()%>%
    
  #change any zeroes, infities, etc. to NA 
  mutate(across(everything(), ~ replace(.x, .x %in% c(0, Inf, -Inf), NA)))
```

Finally, let's combine the well-parcel matches!
```{r}
final_matches_joined_filtered_owners = filtered_parcels_filtered_owners%>%data.frame()%>%dplyr::select(-geom)%>%
  left_join(., final_matches_grouped_by_parcel, by = "my_parcel_num")
```

# Aggregate by owner
We now have our final processed datasets of well-parcel matches and cropland parcels.

We can then aggregate land ownership and well covariates by owner (ex: if one owner has two farms near each other, they would technically show up as separate parcels in our dataset, but we want to consider both parcels under one owner). Grouping by owner also allows us to calculate land area and land value ownership percentiles (ex: 99th percentile is the top percentile of owners who own the most land). 

First, we'll do this at the subbasin level (ex: grouping by owner and subbasin), so that we can calculate inequality metrics at the subbasin level. We also want to make sure that any zeroes or infinites are registered as NA in the dataset so they don't mess up our inequality calculations. 
```{r}
final_matches_grouped_by_subbasin = final_matches_joined_filtered_owners%>%
  group_by(final_owner, subbasin_name)%>%
  reframe(
    num_wells = sum(num_wells),
    well_depth_m = sum(well_depth_m, na.rm = T),
    mean_depth = well_depth_m/num_wells,
    mean_depth_norm = normalised_depth/num_wells,
    normalised_depth = sum(normalised_depth, na.rm = T),
    well_capacity_lps = sum(well_capacity_lps, na.rm = T),
    mean_capacity = well_capacity_lps/num_wells,
    parcel_area_ha = sum(parcel_area_ha, na.rm = T),
    cropland_area = sum(cropland_area, na.rm = T),
    improved_val = sum(improvval, na.rm = T),
    land_val = sum(landval, na.rm = T))%>%
  ungroup()%>%
  mutate(across(everything(), ~ replace(.x, .x %in% c(0, Inf, -Inf), NA)),
         area_percentile = ntile(parcel_area_ha, 100),
         cropland_area_percentile = ntile(cropland_area, 100),
         land_val_percentile = ntile(land_val, 100),
         improved_val_percentile = ntile(improved_val, 100))%>%
  group_by(subbasin_name)%>%
  mutate(subbasin_n = n(), 
         num_wells_z = (num_wells - mean(num_wells, na.rm = T)) / sd(num_wells, na.rm = T),
         depth_z_score = (well_depth_m - mean(well_depth_m, na.rm = T)) / sd(well_depth_m, na.rm = T),
         depth_norm_z_score = (normalised_depth - mean(normalised_depth, na.rm = T)) / sd(normalised_depth, na.rm = T),
         area_z_score = (parcel_area_ha - mean(parcel_area_ha, na.rm = T)) / sd(parcel_area_ha, na.rm = T),
         cropland_area_z_score = (cropland_area - mean(cropland_area, na.rm = T)) / sd(cropland_area, na.rm = T),
         yield_z_score = (well_capacity_lps - mean(well_capacity_lps, na.rm = T)) / sd(well_capacity_lps, na.rm = T),
         landval_z_score = (land_val - mean(land_val, na.rm = T)) / sd(land_val, na.rm = T),
         improved_val_z_score = (improved_val - mean(improved_val, na.rm = T)) / sd(improved_val, na.rm = T),
         area_percentile_z = ntile(area_z_score, 100),
         cropland_area_percentile_z = ntile(cropland_area_z_score, 100),
         land_val_percentile_z = ntile(landval_z_score, 100),
         improved_val_percentile_z = ntile(improved_val_z_score, 100))

cropland_parcels_grouped_by_subbasin = cropland_parcels_filtered_owners%>%
  group_by(cleaned_owner, subbasin_name)%>%
  summarise(num_parcels = n(),
            parcel_area_ha = sum(parcel_area_ha, na.rm = T),
            mean_area_per_parcel = parcel_area_ha/num_parcels,
            cropland_area = sum(cropland_area, na.rm = T),
            improvval = sum(improvval, na.rm = T),
            landval = sum(landval, na.rm = T),
            mean_annual_precip = mean(mean_annual_precip, na.rm = T))%>%
  mutate(across(where(is.numeric), ~ na_if(., 0)))
```

We can also conduct the same process for the entire Central Valley. 
```{r}
final_matches_grouped_overall = final_matches_joined_filtered_owners%>%
  group_by(final_owner)%>%
  reframe(
    num_parcels = n(),
    num_wells = sum(num_wells),
    well_depth_m = sum(well_depth_m, na.rm = T),
    normalised_depth = sum(normalised_depth, na.rm = T),
    max_depth = max(max_depth, na.rm = T),
    max_capacity = max(max_capacity, na.rm = T),
    mean_depth = well_depth_m/num_wells,
    mean_depth_norm = normalised_depth/num_wells,
    well_capacity_lps = sum(well_capacity_lps, na.rm = T),
    mean_capacity = well_capacity_lps/num_wells,
    newest_well = min(newest_well, na.rm = T),
    parcel_area_ha = sum(parcel_area_ha, na.rm = T),
    cropland_area = sum(cropland_area, na.rm = T),
    improved_val = sum(improvval, na.rm = T),
    land_val = sum(landval, na.rm = T))%>%
  ungroup()%>%
  mutate(across(everything(), ~ replace(.x, .x %in% c(0, Inf, -Inf), NA)),
         area_percentile = ntile(parcel_area_ha, 100),
         cropland_area_percentile = ntile(cropland_area, 100),
         land_val_percentile = ntile(land_val, 100),
         improved_val_percentile = ntile(improved_val, 100),
         capacity_percentile = ntile(well_capacity_lps, 100),
         depth_percentile = ntile(well_depth_m, 100))


cropland_parcels_grouped_overall = cropland_parcels_filtered_owners%>%
  mutate(cleaned_owner = ifelse(grepl("WONDERFUL", cleaned_owner), "WONDERFUL", cleaned_owner))%>%
  group_by(cleaned_owner)%>%
  reframe(parcel_area_ha = sum(parcel_area_ha, na.rm = T),
            cropland_area = sum(cropland_area, na.rm = T),
            improvval = sum(improvval, na.rm = T),
            landval = sum(landval, na.rm = T),
            agval = sum(agval, na.rm = T),
            mean_annual_precip = mean(mean_annual_precip, na.rm = T))%>%
  ungroup()%>%
  mutate(across(where(is.numeric), ~ na_if(., 0)),
         area_percentile = ntile(parcel_area_ha, 100),
         cropland_area_percentile = ntile(cropland_area, 100),
         land_val_percentile = ntile(landval, 100),
         improved_val_percentile = ntile(improvval, 100))
```

Let's export these grouped datasets we've just created.

Well-parcel matches
```{r}
write.csv(final_matches_joined_filtered_owners, "Data/Well-parcel matches/final_matches_joined_filtered_owners.csv", row.names = F)
final_matches_joined_filtered_owners = read_csv("Data/Well-parcel matches/final_matches_joined_filtered_owners.csv")

write.csv(final_matches_grouped_by_parcel, "Data/Well-parcel matches/final_matches_grouped_by_parcel.csv", row.names = F)
final_matches_grouped_by_parcel = read.csv("Data/Well-parcel matches/final_matches_grouped_by_parcel.csv")

write.csv(final_matches_grouped_by_subbasin, "Data/Well-parcel matches/final_matches_grouped_by_subbasin.csv", row.names = F)

write.csv(final_matches_grouped_overall, "Data/Well-parcel matches/final_matches_grouped_overall.csv", row.names = F)
final_matches_grouped_overall = read.csv("Data/Well-parcel matches/final_matches_grouped_overall.csv")


write.csv(final_matches_joined_filtered_owners%>%dplyr::select(-c(1:2, parval:cdl_majority_percent, cleaned_owner:final_owner)), "Data/Well-parcel matches/final well-parcel matches, deidentified.csv", row.names = F)


# Calculate centroids
centroids <- st_centroid(polygons)

# Export centroids as a shapefile
st_write(centroids, "centroids.shp", driver = "ESRI Shapefile")
```

Cropland parcels
```{r}
st_write(cropland_parcels_filtered_owners, "Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners.gpkg", delete_dsn = T)
cropland_parcels_filtered_owners = st_read("Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners.gpkg")

st_write(cropland_parcels_grouped_overall, "Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners_grouped_overall.gpkg", delete_dsn = T)
cropland_parcels_grouped_overall = st_read("Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners_grouped_overall.gpkg")

st_write(cropland_parcels_grouped_by_subbasin, "Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners_grouped_by_subbasin.gpkg", delete_dsn = T)

st_write(st_centroid(cropland_parcels_filtered_owners%>%dplyr::select(-c(2:7, 10:50))), "Data/Parcels/Cropland parcels/cropland_parcels_filtered_owners_deidentified.gpkg")
```


# Crop analysis

We bring back our crop raster to calculate the area dedicated to cultivating each crop within each parcel. Within a parcel, we can then also allocate the parcel's total well depth and well capacity across crops proportional to these cultivated areas.

We then classify each crop into crop groups (Legumes, Oil Crops, Fruits, Nuts, Vegetables, and Grains) as well as broader crop groups (Staple or Cash Crop).

Let's first do this for our well-parcel match dataset.
```{r}
results <- exact_extract(
  cropland_extent_raster, 
  filtered_parcels_filtered_owners, 
  include_area = T)

crop_area_summary <- lapply(seq_along(results), function(i) {
  df <- results[[i]] %>%
    group_by(value) %>%  
    summarize(cultivated_area_ha = sum(coverage_fraction * area, na.rm = TRUE)/10000) %>%
    mutate(my_parcel_num = filtered_parcels_filtered_owners$my_parcel_num[i])  # Add parcel ID
  return(df)})

# Combine results into a single dataframe
final_matches_w_crop_precise <- bind_rows(crop_area_summary)%>%
  left_join(., data.frame(levels(cropland_extent_raster)), by = c("value" = "Value"))%>%
  dplyr::select(-value)%>%
  filter(!grepl("Developed|Wetlands|Pasture|Shrubland|Grass Seed|Open Water|Forest|Barren|Aquaculture", Class_Name))%>%
  mutate(
    crop_group = case_when(
      grepl("Chickpea|Dry Beans|Peas|Vetch|Clover", Class_Name) ~ "Legumes",
      grepl("Safflower|Flaxseed|Canola|Sunflower", Class_Name) ~ "Oil Crops",
      grepl("Apple|Appricot|Avocado|Cantaloupe|Cherries|Citrus|Grapes|Nectarines|Peaches|Pears|Plums|Pomegranate|Olive|Watermelon|Melons|Strawberries|Apricots|Oranges|Prunes", Class_Name) ~ "Fruits",
      grepl("Almond|Walnut|Pecan|Pistachio", Class_Name) ~ "Nuts",
      grepl("Broccoli|Cabbage|Carrot|Cucumber|Garlic|Lettuce|Pepper|Onion|Pumpkin|Squash|Tomato|Turnip|Greens|Herbs|Sweet Potatoes|Potatoes", Class_Name) ~ "Vegetables",
      grepl("Barley|Corn|Wheat|Oats|Rice|Rye|Sorghum|Dbl Crop|Triticale", Class_Name) ~ "Grains",
      grepl("Alfalfa", Class_Name) ~ "Alfalfa/Hay"),
    crop_group_broad = case_when(
      crop_group %in% c("Legumes", "Grains") | Class_Name %in% c("Alfalfa", "Other Hay/Non Alfalfa") ~ "Staple",
      crop_group %in% c("Oil Crops", "Fruits", "Vegetables", "Nuts") | grepl("Misc Vegs|Other Tree Crops|Sugarbeets", Class_Name) ~ "Cash Crop"))%>%
  
  left_join(., filtered_parcels_filtered_owners, by = "my_parcel_num")%>%
  left_join(., final_matches_grouped_overall%>%
              dplyr::select(final_owner, area_percentile:depth_percentile), by = "final_owner")%>%
  left_join(., final_matches_grouped_by_parcel, by = "my_parcel_num")%>%
  
  rename(total_parcel_well_depth = well_depth_m, total_parcel_well_capacity = well_capacity_lps)%>%
  mutate(crop_depth = total_parcel_well_depth*cultivated_area_ha/cropland_area,
         crop_depth_norm = (total_parcel_well_depth-num_wells*mean_depth_to_gw) * cultivated_area_ha/cropland_area,
         crop_capacity = total_parcel_well_capacity*cultivated_area_ha/cropland_area)
  
st_write(final_matches_w_crop_precise, "Data/Well-parcel matches/final_matches_w_crop_precise.gpkg", delete_dsn = T)
```


Same with cropland parcels
```{r}
results <- exact_extract(
  cropland_extent_raster, 
  cropland_parcels_filtered_owners, 
  include_area = T)

crop_area_summary <- lapply(seq_along(results), function(i) {
  df <- results[[i]] %>%
    group_by(value) %>%  
    summarize(cultivated_area_ha = sum(coverage_fraction * area, na.rm = TRUE)/10000) %>%
    mutate(my_parcel_num = cropland_parcels_filtered_owners$cropland_parcel_num[i])
  return(df)})

# Combine results into a single dataframe
cropland_parcels_w_crop_precise <- bind_rows(crop_area_summary)%>%
  left_join(., data.frame(levels(cropland_extent_raster)), by = c("value" = "Value"))%>%
  dplyr::select(-value)%>%
  filter(!grepl("Developed|Wetlands|Pasture|Shrubland|Grass Seed|Open Water|Forest|Barren|Aquaculture", Class_Name))%>%
  mutate(
    crop_group = case_when(
      grepl("Chickpea|Dry Beans|Peas|Vetch|Clover", Class_Name) ~ "Legumes",
      grepl("Safflower|Flaxseed|Canola|Sunflower", Class_Name) ~ "Oil Crops",
      grepl("Apple|Appricot|Avocado|Cantaloupe|Cherries|Citrus|Grapes|Nectarines|Peaches|Pears|Plums|Pomegranate|Olive|Watermelon|Melons|Strawberries|Apricots|Oranges|Prunes", Class_Name) ~ "Fruits",
      grepl("Almond|Walnut|Pecan|Pistachio", Class_Name) ~ "Nuts",
      grepl("Broccoli|Cabbage|Carrot|Cucumber|Garlic|Lettuce|Pepper|Onion|Pumpkin|Squash|Tomato|Turnip|Greens|Herbs|Sweet Potatoes|Potatoes", Class_Name) ~ "Vegetables",
      grepl("Barley|Corn|Wheat|Oats|Rice|Rye|Sorghum|Dbl Crop|Triticale", Class_Name) ~ "Grains",
      grepl("Alfalfa", Class_Name) ~ "Alfalfa/Hay"),
    crop_group_broad = case_when(
      crop_group %in% c("Legumes", "Grains") | Class_Name %in% c("Alfalfa", "Other Hay/Non Alfalfa") ~ "Staple",
      crop_group %in% c("Oil Crops", "Fruits", "Vegetables", "Nuts") | grepl("Misc Vegs|Other Tree Crops|Sugarbeets", Class_Name) ~ "Cash Crop"))%>%
  
  left_join(., cropland_parcels_filtered_owners, by = c("my_parcel_num" = "cropland_parcel_num"))%>%
  left_join(., cropland_parcels_grouped_overall%>%dplyr::select(cleaned_owner, area_percentile:improved_val_percentile), by = "cleaned_owner")
  
st_write(cropland_parcels_w_crop_precise, "Data/Parcels/Cropland parcels/cropland_parcels_w_crop_precise.gpkg", delete_dsn = T)
```

# Surface water analysis

We bring in a shapefile of water agency polygons from the [SGMA Data Portal](https://sgma.water.ca.gov/webgis/?appid=SGMADataViewer#boundaries). We want to group the different agencies into categories so that can eventually filter out the agencies that are actually receiving or distributing surface water for irrigation. 

We do this based on a combination of text pattern recognition (ex: if the agency name contains 'irrigation district'), googling any entities whose nature is unclear, and checking out the boundaries of different agencies over satellite imagery to examine whether they overlay cropland. 
```{r}
agencies_all = st_transform(st_read("Data/Water Agencies/i03_WaterDistricts.shp"), crs)%>%
  st_filter(., gw_basins, .pred = st_intersects)%>%
  mutate(agency_type = case_when(
    
    grepl("public water|community|municipal|sewer|utilit|water company|service|csd|water users|sanitary|sanitation|treatment|maintenance|svc. dist|water corporation|mutual water|water system|waste|water works|joint powers|mwc|mutual|md|water association", AGENCYNAME, ignore.case = T) |
     AGENCYNAME %in% c("Nord Road Water Association") ~ "Drinking water and sewage",
    
    grepl("Irrigation|Water District|wd|canal|agricultural|improvement district|storage district|slough|water bank|rio oso|San Joaquin River Exchange|bend district", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("South Delta Water Agency", "Central Delta Water Agency", "North Delta Water Agency")   ~ "Irrigation & water districts",
    
    grepl("conservation district|reclamation district", AGENCYNAME, ignore.case = T) & !grepl("county", AGENCYNAME, ignore.case = T) ~ "Conservation and Reclamation Districts",
    
    grepl("water agency", AGENCYNAME, ignore.case = T) ~
      "Other types of agencies",
    
    grepl("City|county|indian|caltrans|town of|sheriff|state fair|air force|defense|naval|airport", AGENCYNAME, ignore.case = T) ~ "Cities, counties, public land, etc.", 
    
   grepl("school|uc davis|csu|school|college|research|uc davis|kearney", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("Genetic Resource Center") ~  "Education/Research",
   
   grepl("unlimited", AGENCYNAME, ignore.case = T) ~ "Plumbers",
   
    grepl("mobile|trailer|rv park|Mobilodge|reflections rv", AGENCYNAME, ignore.case = T) ~ "Trailer parks",
   
   grepl("conservancy|preserve|parks department|conservation|land trust|reclamation|refuge|wildlife|recreation|park|reserve|preservation", AGENCYNAME, ignore.case = T) ~ "Conservation",
   
   grepl("recreation|hunting|duck|golf|marina|harbor|little league|gun club|wild water adventures|country club|resort|river club|yacht|tuscan ridge|camanche", AGENCYNAME, ignore.case = T) |
     AGENCYNAME %in% c("Gray Lodge Check Station") ~ "Recreation & sport",
   
   grepl("cemetery|hotel|hospital|church|methodist|baptist|medical|motel|alzheimer|fairgrounds|inn", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("Bethel Market") ~ "Other land uses",
   
   grepl("store|gas n save|restaurant|cafe|donut|deli|save mart|travel center|Pappas", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("Gridley Grill") ~ "Stores",
   
   grepl("correctional|prison|labor|justice campus|rehab", AGENCYNAME, ignore.case = T) ~ "Incarceration",
   
   grepl("Care Home|old house|development center", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("Alice Manor", "Feather River Manor") ~ "Residential centres",
   
   grepl("property|properties|apartments|duplexes|homes|apts|homeowners|housing|green valley corporation|estates|village|investments|colony|colonia|elm court|poa|p.o.a.|north davis meadows|villa", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% 
     c("Sunset West Community", "Poplar Avenue Community", "Lakes (The)") ~ "Housing & construction",
   
   grepl("farm|vineyard|ranch|livestock|raisin|foods|growers|feeding|andrews ag|dairy|grape|rice|harvesting|produce|tomato|walnut|riverby limited|Batth|winery|hungry|enclave|vina|garlic|sugar company|opal fry|oji|britz", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("AZCAL MANAGEMENT CO\r\n", "Bar 20 Partner", "Klsy LLC", "Hanot Foundation Inc", "Simplot Company", "Hershey Land Company", "Proberta", "Dantoni Area") ~"Individual ranches, farms, etc",
   
   grepl("pumping plan", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("Norfield Industries", "Colusa Tractor Company", "MP Associates", "Guardian Industries Corp", "Saf-T-Cab") ~ "Industrial",
   
   grepl("Energy", AGENCYNAME, ignore.case = T) ~ "Energy & drilling",
   
   grepl("packing|packers|cold storage", AGENCYNAME, ignore.case = T) | AGENCYNAME %in% c("Smuckers Quality Beverages", "Styro-Tek") ~ "Food Packaging & agritech",
   OBJECTID %in% c(3679:3683) ~ "gibberish",
   
   AGENCYNAME %in% c("Bay Standards", "Bon Gustos", "Cherry Auction", "Anglers Subdivision 4", "Porterville-Jones Corner", "Four Twenty 420 Club",
                     "Meyer Crest", "WATERFORD-RIVER POINTE", "WATERFORD - HICKMAN") | grepl("Corners|Gardens District|tract mutual|mhp|flournoy|plano|casa loma|gilsizer|southwest tract|
                                                                                             sierra vista|san juan vista|san luis hills|sunset oaks|OID|neill forebay|san juan vista|hegan lane|
                                                                                             beacon west|fremont one|convalescent|sunset moulding|north kranenburg|
                                                                                             SA 14 CHUK CHANSE SUBDIVISION|National American Corporation", AGENCYNAME, ignore.case = T) 
   ~ "Other (to exclude based on satellite view)",
   
   OBJECTID <= 521   ~ "Individuals and family trusts",
   
   T ~ "Unclear"))

write.csv(agencies_all%>%data.frame()%>%dplyr::select(AGENCYNAME, agency_type), "agencies_categorised.csv", row.names = F)
```

```{r}
agencies_all%>%
  #filter(agency_type == "Conservation and Reclamation Districts")%>%
  filter(grepl("South Delta", AGENCYNAME))%>%
  data.frame()
    
```


```{r}
tm_shape(agencies_all%>%
           filter(AGENCYNAME == "Central San Joaquin Water Conservation District"))+
  tm_borders(lwd = 10, "black")+
  tm_basemap("Esri.WorldImagery")
```

Filter only the groups that can reasonably assumed to be receiving surface water for irrigation, based on the above examination
```{r}
agencies_filtered = agencies_all%>%
  filter(agency_type %in% c("Irrigation & water districts", "Individuals and family trusts", "Individual ranches, farms, etc", "Conservation and Reclamation Districts"))

agencies_filtered%>%data.frame()%>%arrange(AGENCYNAME)
```

Use a spatial join to see if each cropland parcel intersects one of these surface water districts or not. 
```{r}
cropland_parcels_with_agencies = cropland_parcels_filtered_owners%>%
  st_join(., agencies_filtered%>%dplyr::select(AGENCYNAME, agency_type), join = st_intersects, largest = T)%>%
  mutate(sw_parcel = ifelse(!is.na(AGENCYNAME), 1, 0))

st_write(cropland_parcels_with_agencies, "Data/Parcels/Cropland parcels/cropland_parcels_with_sw_agencies.gpkg", delete_dsn = T)
cropland_parcels_with_agencies = st_read("Data/Parcels/Cropland parcels/cropland_parcels_with_sw_agencies.gpkg")
```

We can do the same with well-parcel matches to examine how intersection with surface water districts varies by percentile of well depth and well capacity owned.
```{r}
parcels_with_agencies = filtered_parcels_filtered_owners%>%
  left_join(., final_matches_grouped_by_parcel, by = "my_parcel_num")%>%
  left_join(., final_matches_grouped_overall%>%rename_with(~ str_c("owner_", .), .cols = -final_owner), by = "final_owner")%>%
  st_join(., agencies_filtered%>%dplyr::select(AGENCYNAME, agency_type), join = st_intersects, largest = T)%>%
  mutate(sw_parcel = ifelse(!is.na(AGENCYNAME), 1, 0))

st_write(parcels_with_agencies, "Data/Parcels/Filtered parcels/filtered_parcels_with_sw_agencies.gpkg")
parcels_with_agencies = st_read("Data/Parcels/Filtered parcels/filtered_parcels_with_sw_agencies.gpkg")
```

# Archive

In case it's needed to calculate most grown crop per parcel (rather than dividing up a parcel into different crops)
```{r}
cropland_parcels_w_crop_mode = cropland_parcels_filtered_owners%>%
  mutate(crop_mode = exact_extract(cropland_extent_raster, cropland_parcels_filtered_owners, fun = "mode", progress = TRUE))%>%
  left_join(., data.frame(levels(cropland_extent_raster)), by = c("crop_mode" = "Value"))%>%
  filter(!grepl("Developed|Wetlands|Pasture|Shrubland|Grass Seed|Open Water|Forest|Barren|Aquaculture", Class_Name))%>%
  
  mutate(
    crop_group = case_when(
      grepl("Chickpea|Dry Beans|Peas|Vetch|Clover", Class_Name) ~ "Legumes",
      grepl("Safflower|Flaxseed|Canola|Sunflower", Class_Name) ~ "Oil Crops",
      grepl("Apple|Appricot|Avocado|Cantaloupe|Cherries|Citrus|Grapes|Nectarines|Peaches|Pears|Plums|Pomegranate|Olive|Watermelon|Melons|Strawberries|Apricots|Oranges|Prunes", Class_Name) ~ "Fruits",
      grepl("Almond|Walnut|Pecan|Pistachio", Class_Name) ~ "Nuts",
      grepl("Broccoli|Cabbage|Carrot|Cucumber|Garlic|Lettuce|Pepper|Onion|Pumpkin|Squash|Tomato|Turnip|Greens|Herbs|Sweet Potatoes|Potatoes", Class_Name) ~ "Vegetables",
      grepl("Barley|Corn|Wheat|Oats|Rice|Rye|Sorghum|Dbl Crop|Triticale", Class_Name) ~ "Grains",
      grepl("Alfalfa", Class_Name) ~ "Alfalfa/Hay"),
    crop_group_broad = case_when(
      crop_group %in% c("Legumes", "Grains") | Class_Name %in% c("Alfalfa", "Other Hay/Non Alfalfa") ~ "Staple",
      crop_group %in% c("Oil Crops", "Fruits", "Vegetables", "Nuts") | grepl("Misc Vegs|Other Tree Crops|Sugarbeets", Class_Name) ~ "Cash Crop"))%>%
  
  left_join(., cropland_parcels_grouped_overall%>%
  mutate(area_percentile = ntile(parcel_area_ha, 100),
         cropland_area_percentile = ntile(cropland_area, 100),
         land_val_percentile = ntile(landval, 100),
         improved_val_percentile = ntile(improvval, 100))%>%
  select(cleaned_owner, area_percentile:improved_val_percentile), by = "cleaned_owner")

st_write(cropland_parcels_w_crop_mode, "Data/Parcels/Cropland parcels/cropland_parcels_cropmode_final.gpkg", delete_dsn = T)
```
